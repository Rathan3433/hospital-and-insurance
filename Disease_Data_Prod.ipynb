{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c2bd184-a541-44fa-857c-039f15d1305e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "006851fe-135d-44a2-a4ae-733f0502e14b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.ksrdatadlsa.dfs.core.windows.net\",\n",
    "    dbutils.secrets.get(scope=\"optumscope1\", key=\"optumkeysstore\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82eca4b1-e2d4-4b2f-9681-f4c6f07e1d5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Disease = spark.read.csv(\"abfss://optumdata@ksrdatadlsa.dfs.core.windows.net/RawData/disease.csv\",header=True, inferSchema=True,escape='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c3f24ba-cf5b-4004-8c07-3b21fe7de539",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "Group = Group.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46d49199-5838-4bd1-9bd1-78d6c3b4de89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(60, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to verify Rows count and Cloumn Count\n",
    "Group.count(),len(Group.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca51b602-72cd-4346-a4c4-f355503303d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+\n|subgrp_id|disease_id|disease_name|\n+---------+----------+------------+\n|        0|         0|           0|\n+---------+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# To find null values\n",
    "Disease.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in Disease.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97360550-b6f2-4782-9c57-18a43e3a2290",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Count of subgrp_id column: 10\nNull values Count of subgrp_id column: 0\n\nsubgrp_id Column Start With Number: 0\nsubgrp_id Column Start With String: 60\nsubgrp_id Column Start With Spl.Cha: 0\nsubgrp_id Column contains string values: 60\nsubgrp_id Column contains number values: 60\nsubgrp_id Column contains Spl.Char values: 0\n\nDistinct Count of disease_id column: 60\nNull values Count of disease_id column: 0\n\ndisease_id Column Start With Number: 60\ndisease_id Column Start With String: 0\ndisease_id Column Start With Spl.Cha: 0\ndisease_id Column contains string values: 0\ndisease_id Column contains number values: 60\ndisease_id Column contains Spl.Char values: 0\n\nDistinct Count of disease_name column: 60\nNull values Count of disease_name column: 0\n\ndisease_name Column Start With Number: 0\ndisease_name Column Start With String: 60\ndisease_name Column Start With Spl.Cha: 0\ndisease_name Column contains string values: 60\ndisease_name Column contains number values: 0\ndisease_name Column contains Spl.Char values: 21\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, asc\n",
    "\n",
    "def analyze_columns(df):\n",
    "    columns = df.columns\n",
    "    for column in columns:\n",
    "        distinct_count = df.select(column).distinct().count()\n",
    "        null_count = df.filter(col(column).isNull()).count()\n",
    "        numeric_count = df.filter(col(column).rlike(\"^[0-9]\")).count()\n",
    "        text_count = df.filter(col(column).rlike(\"^[A-Za-z]\")).count()\n",
    "        special_char_count = df.filter(~col(column).rlike(\"^[A-Za-z0-9]\")).count()\n",
    "        contains_string = df.filter(col(column).rlike(\"[A-Za-z]\")).count()\n",
    "        contains_number = df.filter(col(column).rlike(\"[0-9]\")).count()\n",
    "        contains_spl_char = df.filter(col(column).rlike(\"[^A-Za-z0-9]\")).count()\n",
    "\n",
    "        print(\"Distinct Count of {} column: {}\".format(column, distinct_count))\n",
    "        print(\"Null values Count of {} column: {}\\n\".format(column, null_count))\n",
    "        print(\"{} Column Start With Number: {}\".format(column, numeric_count))\n",
    "        print(\"{} Column Start With String: {}\".format(column, text_count))\n",
    "        print(\"{} Column Start With Spl.Cha: {}\".format(column, special_char_count))\n",
    "        print(\"{} Column contains string values: {}\".format(column, contains_string))\n",
    "        print(\"{} Column contains number values: {}\".format(column, contains_number))\n",
    "        print(\"{} Column contains Spl.Char values: {}\\n\".format(column, contains_spl_char))\n",
    "        \n",
    "# Example usage:\n",
    "analyze_columns(Disease)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f17a5a1-2666-476d-9c1d-9878de94aca6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the output container path\n",
    "output_container_path = \"abfss://optumdata@ksrdatadlsa.dfs.core.windows.net/StatgingData\"\n",
    "\n",
    "# Write the DataFrame to the output container path\n",
    "Disease.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").format(\"com.databricks.spark.csv\").save(output_container_path)\n",
    "\n",
    "# List files in the output container path\n",
    "files = dbutils.fs.ls(output_container_path)\n",
    "\n",
    "# Filter out the output file\n",
    "output_file = [x for x in files if x.name.startswith(\"part-\")]\n",
    "\n",
    "# Move the output file to a specific location\n",
    "dbutils.fs.mv(output_file[0].path, \"%s/stg_Disease.csv\" % output_container_path)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Disease_Data_Prod",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
